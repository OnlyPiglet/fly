package queue_tools

import (
	"encoding/json"
	"sync/atomic"
	"testing"
	"time"

	"github.com/OnlyPiglet/fly/redistools"
)

type dv struct {
	Abcdefgh string `json:"abcdefgh"`
	Abcdef   bool   `json:"abcdef"`
}

type SV struct {
	A string
}

func (S SV) MarshalBinary() (data []byte, err error) {
	return json.Marshal(S)
}

func (S SV) UnmarshalBinary(data []byte) error {
	return json.Unmarshal(data, &S)
}

type SVS []SV

func (S SVS) MarshalBinary() (data []byte, err error) {
	return json.Marshal(S)
}

func (S SVS) UnmarshalBinary(data []byte) error {
	return json.Unmarshal(data, &S)
}

func TestEnQueueWithSize(t *testing.T) {
	single, err := redistools.InitSingle("127.0.0.1:6379", "", "", 1)
	if err != nil {
		t.Error(err)
	}
	queue := NewRedisQueue[SV]("abc", single, 5, 300*time.Millisecond)
	err = queue.Enqueue([]SV{
		{"1"}, {"2"}, {"2"}, {"2"}, {"2"}, {"2"}, {"2"}, {"2"}, {"2"}, {"2"},
	})
	if err != nil {
		t.Error(err)
	}
}

func TestEnQueueWithoutSize(t *testing.T) {
	single, err := redistools.InitSingle("127.0.0.1:6379", "", "", 1)
	if err != nil {
		t.Error(err)
	}
	queue := NewRedisQueue[SV]("abc", single, 0, 300*time.Millisecond)
	err = queue.Enqueue([]SV{
		{"1"}, {"2"}, {"2"}, {"2"}, {"2"}, {"2"}, {"2"}, {"2"}, {"2"}, {"2"},
	})
	if err != nil {
		t.Error(err)
	}
}

func TestProductAndCustomer(t *testing.T) {
	dvs := make([]dv, 0, 10000)
	for i := 0; i < 10000; i++ {
		dvs = append(dvs, dv{
			Abcdefgh: "2ba2d4bd-af24-48ae-9e66-22d1c30c9f01",
			Abcdef:   true,
		})
	}
	//single, err := redistools.InitSingle("r-bp1dqgkbwcsqyto3lcpd.redis.rds.aliyuncs.com:6379", "r-bp1dqgkbwcsqyto3lc", "4553283@wch", 0)
	single, err := redistools.InitSingle("127.0.0.1:6379", "", "", 0)

	if err != nil {
		t.Error(err)
	}

	ts := time.Now()

	// ä¿®å¤æ–¹æ¡ˆï¼š
	// 1. ç§»é™¤å®¹é‡é™åˆ¶ï¼ˆæ”¹ä¸º 0 æˆ– -1ï¼‰æˆ–å¢å¤§å®¹é‡åˆ° 1000000+
	// 2. åˆ†æ‰¹å†™å…¥ï¼Œæ¯æ‰¹ 5000 æ¡ï¼Œé¿å…å•æ¬¡ä¼ è¾“æ•°æ®é‡è¿‡å¤§
	queue := NewRedisQueue[dv]("abc", single, 0, 30000*time.Millisecond) // å®¹é‡æ”¹ä¸º 0ï¼ˆæ— é™åˆ¶ï¼‰

	batchSize := 10000 // æ¯æ‰¹ 5000 æ¡
	totalBatches := (len(dvs) + batchSize - 1) / batchSize

	t.Logf("å¼€å§‹åˆ†æ‰¹å†™å…¥: æ€»æ•°=%d, æ‰¹æ¬¡å¤§å°=%d, æ‰¹æ¬¡æ•°=%d", len(dvs), batchSize, totalBatches)

	for i := 0; i < len(dvs); i += batchSize {
		end := i + batchSize
		if end > len(dvs) {
			end = len(dvs)
		}

		batch := dvs[i:end]
		err = queue.Enqueue(batch)
		if err != nil {
			t.Errorf("æ‰¹æ¬¡ %d-%d å†™å…¥å¤±è´¥: %v", i, end, err)
			return
		}

		if (i/batchSize+1)%20 == 0 { // æ¯ 20 æ‰¹è¾“å‡ºä¸€æ¬¡è¿›åº¦
			t.Logf("å·²å†™å…¥: %d / %d (%.1f%%)", end, len(dvs), float64(end)*100/float64(len(dvs)))
		}
	}

	sub := time.Now().Sub(ts)
	t.Logf("âœ“ å†™å…¥å®Œæˆ! æ€»è€—æ—¶: %d ms (%.2f ç§’)", sub.Milliseconds(), sub.Seconds())
	t.Logf("  å¹³å‡é€Ÿåº¦: %.0f æ¡/ç§’", float64(len(dvs))/sub.Seconds())

	// éªŒè¯é˜Ÿåˆ—é•¿åº¦
	queueLen, err := queue.Len()
	if err != nil {
		t.Errorf("è·å–é˜Ÿåˆ—é•¿åº¦å¤±è´¥: %v", err)
	} else {
		t.Logf("  é˜Ÿåˆ—æœ€ç»ˆé•¿åº¦: %d", queueLen)
	}
}

// TestProductAndCustomer_SmallBatch å°æ‰¹é‡æµ‹è¯•ï¼ˆç”¨äºå¿«é€ŸéªŒè¯ï¼‰
func TestProductAndCustomer_SmallBatch(t *testing.T) {
	dvs := make([]dv, 0, 10000)
	for i := 0; i < 10000; i++ {
		dvs = append(dvs, dv{
			Abcdefgh: "2ba2d4bd-af24-48ae-9e66-22d1c30c9f01",
			Abcdef:   true,
		})
	}

	single, err := redistools.InitSingle("r-bp1dqgkbwcsqyto3lcpd.redis.rds.aliyuncs.com:6379", "r-bp1dqgkbwcsqyto3lc", "4553283@wch", 0)
	if err != nil {
		t.Error(err)
		return
	}

	ts := time.Now()

	// å°æ‰¹é‡æµ‹è¯•ï¼š1 ä¸‡æ¡æ•°æ®
	queue := NewRedisQueue[dv]("abc_small", single, 0, 10000*time.Millisecond)

	batchSize := 1000
	totalBatches := (len(dvs) + batchSize - 1) / batchSize

	t.Logf("å°æ‰¹é‡æµ‹è¯•: æ€»æ•°=%d, æ‰¹æ¬¡å¤§å°=%d, æ‰¹æ¬¡æ•°=%d", len(dvs), batchSize, totalBatches)

	for i := 0; i < len(dvs); i += batchSize {
		end := i + batchSize
		if end > len(dvs) {
			end = len(dvs)
		}

		batch := dvs[i:end]
		err = queue.Enqueue(batch)
		if err != nil {
			t.Errorf("æ‰¹æ¬¡ %d-%d å†™å…¥å¤±è´¥: %v", i, end, err)
			return
		}
	}

	sub := time.Now().Sub(ts)
	t.Logf("âœ“ å°æ‰¹é‡æµ‹è¯•å®Œæˆ! è€—æ—¶: %d ms", sub.Milliseconds())

	queueLen, _ := queue.Len()
	t.Logf("  é˜Ÿåˆ—é•¿åº¦: %d", queueLen)
}

// TestProductAndCustomer_CapacityLimit æµ‹è¯•å®¹é‡é™åˆ¶
func TestProductAndCustomer_CapacityLimit(t *testing.T) {
	single, err := redistools.InitSingle("r-bp1dqgkbwcsqyto3lcpd.redis.rds.aliyuncs.com:6379", "r-bp1dqgkbwcsqyto3lc", "4553283@wch", 0)
	if err != nil {
		t.Error(err)
		return
	}

	// æµ‹è¯•å®¹é‡é™åˆ¶ï¼šé˜Ÿåˆ—å®¹é‡ 100ï¼Œå°è¯•å†™å…¥ 150 æ¡
	queue := NewRedisQueue[dv]("abc_capacity_test", single, 100, 5000*time.Millisecond)

	t.Log("=== æµ‹è¯•1: å†™å…¥ 50 æ¡ï¼ˆåº”è¯¥æˆåŠŸï¼‰===")
	batch1 := make([]dv, 50)
	for i := 0; i < 50; i++ {
		batch1[i] = dv{Abcdefgh: "test1", Abcdef: true}
	}
	err = queue.Enqueue(batch1)
	if err != nil {
		t.Errorf("âŒ ç¬¬ä¸€æ‰¹å†™å…¥å¤±è´¥: %v", err)
	} else {
		queueLen, _ := queue.Len()
		t.Logf("âœ“ ç¬¬ä¸€æ‰¹å†™å…¥æˆåŠŸï¼Œé˜Ÿåˆ—é•¿åº¦: %d", queueLen)
	}

	t.Log("\n=== æµ‹è¯•2: å†å†™å…¥ 40 æ¡ï¼ˆåº”è¯¥æˆåŠŸï¼‰===")
	batch2 := make([]dv, 40)
	for i := 0; i < 40; i++ {
		batch2[i] = dv{Abcdefgh: "test2", Abcdef: false}
	}
	err = queue.Enqueue(batch2)
	if err != nil {
		t.Errorf("âŒ ç¬¬äºŒæ‰¹å†™å…¥å¤±è´¥: %v", err)
	} else {
		queueLen, _ := queue.Len()
		t.Logf("âœ“ ç¬¬äºŒæ‰¹å†™å…¥æˆåŠŸï¼Œé˜Ÿåˆ—é•¿åº¦: %d", queueLen)
	}

	t.Log("\n=== æµ‹è¯•3: å†å†™å…¥ 20 æ¡ï¼ˆåº”è¯¥å¤±è´¥ï¼šè¶…å‡ºå®¹é‡ï¼‰===")
	batch3 := make([]dv, 20)
	for i := 0; i < 20; i++ {
		batch3[i] = dv{Abcdefgh: "test3", Abcdef: true}
	}
	err = queue.Enqueue(batch3)
	if err != nil {
		t.Logf("âœ“ ç¬¬ä¸‰æ‰¹å†™å…¥å¤±è´¥ï¼ˆç¬¦åˆé¢„æœŸï¼‰: %v", err)
	} else {
		t.Error("âŒ ç¬¬ä¸‰æ‰¹å†™å…¥æˆåŠŸäº†ï¼Œä½†åº”è¯¥å¤±è´¥ï¼ˆé˜Ÿåˆ—å®¹é‡è¶…é™ï¼‰")
	}
}

// TestConcurrentWrite_PressureTest å¤šå®ä¾‹å¹¶å‘å†™å…¥å‹åŠ›æµ‹è¯•
// åœºæ™¯ï¼šå¤šä¸ªç”Ÿäº§è€…å¹¶å‘å†™å…¥ï¼ŒæŒç»­10åˆ†é’Ÿï¼Œæ¯5ç§’å†™å…¥ä¸€æ‰¹ï¼Œè§‚å¯ŸRedisæ€§èƒ½
func TestConcurrentWrite_PressureTest(t *testing.T) {
	// ä½¿ç”¨æœ¬åœ° Redisï¼ˆæ”¹ä¸ºè¿œç¨‹åœ°å€æµ‹è¯•è¿œç¨‹ Redisï¼‰
	single, err := redistools.InitSingle("127.0.0.1:6379", "", "", 0)
	if err != nil {
		t.Error(err)
		return
	}

	// é…ç½®å‚æ•°
	const (
		numWorkers       = 10               // å¹¶å‘å†™å…¥çš„ worker æ•°é‡
		numConsumers     = 10               // å¹¶å‘æ¶ˆè´¹è€…æ•°é‡ï¼ˆå»ºè®®ä¸ç”Ÿäº§è€…æ•°é‡ç›¸å½“ï¼‰
		batchSize        = 1000             // æ¯æ‰¹å†™å…¥çš„æ•°æ®é‡
		consumeBatchSize = 100              // æ¯æ¬¡æ‰¹é‡æ¶ˆè´¹çš„æ•°æ®é‡ âš¡
		writeInterval    = 5 * time.Second  // æ¯ 5 ç§’å†™å…¥ä¸€æ¬¡
		testDuration     = 10 * time.Minute // æŒç»­ 10 åˆ†é’Ÿ
		queueCapacity    = 0                // æ— å®¹é‡é™åˆ¶
		redisTimeout     = 30 * time.Second // Redis æ“ä½œè¶…æ—¶
		consumeLogEvery  = 10000            // æ¯æ¶ˆè´¹å¤šå°‘æ¡æ‰“å°ä¸€æ¬¡æ—¥å¿—
	)

	t.Logf("=== ğŸš€ æ‰¹é‡æ¶ˆè´¹å‹åŠ›æµ‹è¯•é…ç½® ===")
	t.Logf("  âš™ï¸  ç”Ÿäº§é…ç½®:")
	t.Logf("     - ç”Ÿäº§è€…æ•°é‡: %d", numWorkers)
	t.Logf("     - ç”Ÿäº§æ‰¹æ¬¡: %d æ¡/æ‰¹", batchSize)
	t.Logf("     - å†™å…¥é—´éš”: %s", writeInterval)
	t.Logf("  âš¡ æ¶ˆè´¹é…ç½® (æ‰¹é‡æ¨¡å¼):")
	t.Logf("     - æ¶ˆè´¹è€…æ•°é‡: %d", numConsumers)
	t.Logf("     - æ¶ˆè´¹æ‰¹æ¬¡: %d æ¡/æ‰¹ â† å…³é”®ä¼˜åŒ–ï¼", consumeBatchSize)
	t.Logf("  ğŸ“Š é¢„æµ‹:")
	expectedTotal := numWorkers * batchSize * int(testDuration/writeInterval)
	t.Logf("     - ç†è®ºç”Ÿäº§: %d æ¡/10åˆ†é’Ÿ (~%.0f æ¡/ç§’)", expectedTotal, float64(numWorkers*batchSize)/writeInterval.Seconds())
	t.Logf("     - ç†è®ºæ¶ˆè´¹: ~%d æ¡/ç§’ (å•æ¬¡æ‰¹é‡Ã—æ¶ˆè´¹è€…æ•°)", numConsumers*consumeBatchSize*10) // å‡è®¾æ¯æ¬¡10ms
	t.Logf("  â±ï¸  æµ‹è¯•æ—¶é•¿: %s", testDuration)
	t.Logf("")

	// åˆ›å»ºé˜Ÿåˆ—
	queue := NewRedisQueue[dv]("pressure_test", single, queueCapacity, redisTimeout)

	// æ¸…ç©ºé˜Ÿåˆ—ï¼ˆé¿å…ä¹‹å‰æµ‹è¯•çš„æ•°æ®å½±å“ï¼‰
	t.Log("æ¸…ç©ºæ—§æ•°æ®...")
	for {
		_, err := queue.Dequeue()
		if err != nil {
			break
		}
	}

	// ç»Ÿè®¡ä¿¡æ¯
	type Stats struct {
		TotalWrites   int64
		TotalRecords  int64
		SuccessWrites int64
		FailedWrites  int64
		TotalDuration time.Duration
		MaxDuration   time.Duration
		MinDuration   time.Duration
		Errors        []string
	}

	stats := make([]Stats, numWorkers)
	for i := range stats {
		stats[i].MinDuration = time.Hour // åˆå§‹åŒ–ä¸ºä¸€ä¸ªå¤§å€¼
	}

	// æ¶ˆè´¹è€…ç»Ÿè®¡
	var consumerCount int64  // æ€»æ¶ˆè´¹æ•°é‡
	var consumerErrors int64 // æ¶ˆè´¹å¤±è´¥æ•°é‡
	var _ time.Time          // æœ€åä¸€æ¬¡æ¶ˆè´¹æ—¶é—´

	startTime := time.Now()
	stopChan := make(chan struct{})
	consumerStopChan := make(chan struct{})
	consumerDoneChan := make(chan bool, numConsumers)
	doneChan := make(chan int, numWorkers)

	// å¯åŠ¨å¤šä¸ªæ‰¹é‡æ¶ˆè´¹è€…åç¨‹
	t.Logf("ğŸ”„ å¯åŠ¨ %d ä¸ªæ‰¹é‡æ¶ˆè´¹è€…åç¨‹ï¼ˆæ¯æ¬¡æ¶ˆè´¹ %d æ¡ï¼‰...\n", numConsumers, consumeBatchSize)
	for consumerID := 0; consumerID < numConsumers; consumerID++ {
		go func(id int) {
			defer func() {
				consumerDoneChan <- true
			}()

			consecutiveErrors := 0
			maxConsecutiveErrors := 5 // è¿ç»­å¤±è´¥5æ¬¡åï¼Œæš‚åœä¸€ä¸‹
			localConsumeCount := int64(0)
			localBatchCount := int64(0)

			for {
				select {
				case <-consumerStopChan:
					t.Logf("ğŸ›‘ æ¶ˆè´¹è€…-%d åœæ­¢ | æœ¬åœ°æ¶ˆè´¹: %d æ¡ (åˆ† %d æ‰¹)", id, localConsumeCount, localBatchCount)
					return
				default:
					// æ‰¹é‡æ¶ˆè´¹ - æ¯æ¬¡å°è¯•æ¶ˆè´¹ consumeBatchSize æ¡
					items, err := queue.DequeueBatch(consumeBatchSize)
					if err != nil || len(items) == 0 {
						// é˜Ÿåˆ—ä¸ºç©ºæˆ–å…¶ä»–é”™è¯¯
						consecutiveErrors++
						if err != nil {
							atomic.AddInt64(&consumerErrors, 1)
						}

						// å¦‚æœè¿ç»­å¤±è´¥å¤šæ¬¡ï¼Œè¯´æ˜é˜Ÿåˆ—å¯èƒ½é•¿æ—¶é—´ä¸ºç©ºï¼Œç¨å¾®ä¼‘æ¯ä¸€ä¸‹
						if consecutiveErrors >= maxConsecutiveErrors {
							time.Sleep(50 * time.Millisecond) // æ‰¹é‡æ¶ˆè´¹æ—¶å¯ä»¥æ›´é¢‘ç¹é‡è¯•
							consecutiveErrors = 0
						}
						continue
					}

					// æ‰¹é‡æ¶ˆè´¹æˆåŠŸ
					consecutiveErrors = 0
					batchCount := int64(len(items))
					localConsumeCount += batchCount
					localBatchCount++
					totalCount := atomic.AddInt64(&consumerCount, batchCount)

					// åªæ‰“å°å†…å®¹ï¼Œä¸åšä»»ä½•å¤„ç†ï¼ˆæŒ‰é…ç½®çš„é¢‘ç‡æ‰“å°æ—¥å¿—ï¼‰
					if totalCount%int64(consumeLogEvery) < batchCount || totalCount == batchCount {
						t.Logf("âš¡ [æ¶ˆè´¹è€…-%d] æ‰¹é‡: %dæ¡ | ç´¯è®¡: %dæ¡ | æ•°æ®: %s",
							id, batchCount, totalCount, items[0].Abcdefgh)
					}
				}
			}
		}(consumerID)
	}

	// å¯åŠ¨ç»Ÿè®¡è¾“å‡ºåç¨‹
	go func() {
		ticker := time.NewTicker(30 * time.Second)
		defer ticker.Stop()

		for {
			select {
			case <-ticker.C:
				elapsed := time.Since(startTime)
				var totalWrites, totalRecords, successWrites, failedWrites int64
				var totalDuration, maxDuration time.Duration
				minDuration := time.Hour

				for i := 0; i < numWorkers; i++ {
					totalWrites += stats[i].TotalWrites
					totalRecords += stats[i].TotalRecords
					successWrites += stats[i].SuccessWrites
					failedWrites += stats[i].FailedWrites
					totalDuration += stats[i].TotalDuration
					if stats[i].MaxDuration > maxDuration {
						maxDuration = stats[i].MaxDuration
					}
					if stats[i].MinDuration < minDuration && stats[i].MinDuration > 0 {
						minDuration = stats[i].MinDuration
					}
				}

				queueLen, _ := queue.Len()
				avgDuration := time.Duration(0)
				if totalWrites > 0 {
					avgDuration = totalDuration / time.Duration(totalWrites)
				}

				progress := elapsed.Minutes() / testDuration.Minutes() * 100
				currentConsumerCount := atomic.LoadInt64(&consumerCount)
				currentConsumerErrors := atomic.LoadInt64(&consumerErrors)

				t.Logf("\nâ±ï¸  [è¿›åº¦æŠ¥å‘Š] å·²è¿è¡Œ: %.1f åˆ†é’Ÿ / %.0f åˆ†é’Ÿ (%.1f%%)",
					elapsed.Minutes(), testDuration.Minutes(), progress)
				t.Logf("  ğŸ“Š ç”Ÿäº§è€…ç»Ÿè®¡:")
				t.Logf("     - æ€»å†™å…¥æ¬¡æ•°: %d", totalWrites)
				t.Logf("     - æ€»è®°å½•æ•°: %d", totalRecords)
				t.Logf("     - æˆåŠŸ/å¤±è´¥: %d / %d", successWrites, failedWrites)
				if totalWrites > 0 {
					t.Logf("     - æˆåŠŸç‡: %.2f%%", float64(successWrites)*100/float64(totalWrites))
				}
				t.Logf("  ğŸ½ï¸  æ¶ˆè´¹è€…ç»Ÿè®¡ (æ‰¹é‡æ¨¡å¼ %dæ¡/æ¬¡):", consumeBatchSize)
				t.Logf("     - å·²æ¶ˆè´¹: %d æ¡", currentConsumerCount)
				t.Logf("     - æ¶ˆè´¹é€Ÿåº¦: %.0f æ¡/ç§’ âš¡", float64(currentConsumerCount)/elapsed.Seconds())
				t.Logf("     - æ¶ˆè´¹é”™è¯¯: %d æ¬¡ (ç©ºé˜Ÿåˆ—å°è¯•)", currentConsumerErrors)
				if totalRecords > 0 {
					consumeRatio := float64(currentConsumerCount) / float64(totalRecords) * 100
					t.Logf("     - æ¶ˆè´¹è¿›åº¦: %.2f%%", consumeRatio)
					produceSpeed := float64(totalRecords) / elapsed.Seconds()
					consumeSpeed := float64(currentConsumerCount) / elapsed.Seconds()
					if produceSpeed > 0 {
						t.Logf("     - æ¶ˆè´¹/ç”Ÿäº§æ¯”: %.2f%% (>100%%ä¸ºæ¶ˆè´¹å¿«)", consumeSpeed/produceSpeed*100)
					}
				}
				t.Logf("  âš¡ æ€§èƒ½æŒ‡æ ‡:")
				t.Logf("     - ç”Ÿäº§é€Ÿåº¦: %.0f æ¡/ç§’", float64(totalRecords)/elapsed.Seconds())
				t.Logf("     - å¹³å‡å†™å…¥è€—æ—¶: %s", avgDuration)
				t.Logf("     - æœ€å¿«/æœ€æ…¢: %s / %s", minDuration, maxDuration)
				t.Logf("  ğŸ“¦ é˜Ÿåˆ—çŠ¶æ€:")
				t.Logf("     - å½“å‰é˜Ÿåˆ—é•¿åº¦: %d", queueLen)
				t.Logf("     - å †ç§¯é‡: ç”Ÿäº§ %d - æ¶ˆè´¹ %d = %d", totalRecords, currentConsumerCount, totalRecords-currentConsumerCount)
				t.Logf("")

			case <-stopChan:
				return
			}
		}
	}()

	// å¯åŠ¨å¤šä¸ªå¹¶å‘ worker
	t.Logf("ğŸš€ å¯åŠ¨ %d ä¸ªå¹¶å‘ Worker...\n", numWorkers)

	for workerID := 0; workerID < numWorkers; workerID++ {
		go func(id int) {
			ticker := time.NewTicker(writeInterval)
			defer ticker.Stop()

			timeout := time.After(testDuration)

			for {
				select {
				case <-timeout:
					doneChan <- id
					return

				case <-ticker.C:
					batch := make([]dv, batchSize)
					for i := 0; i < batchSize; i++ {
						batch[i] = dv{
							Abcdefgh: "2ba2d4bd-af24-48ae-9e66-22d1c30c9f01",
							Abcdef:   true,
						}
					}

					writeStart := time.Now()
					err := queue.Enqueue(batch)
					writeDuration := time.Since(writeStart)

					stats[id].TotalWrites++
					stats[id].TotalRecords += int64(batchSize)
					stats[id].TotalDuration += writeDuration

					if writeDuration > stats[id].MaxDuration {
						stats[id].MaxDuration = writeDuration
					}
					if writeDuration < stats[id].MinDuration {
						stats[id].MinDuration = writeDuration
					}

					if err != nil {
						stats[id].FailedWrites++
						errMsg := err.Error()
						if len(stats[id].Errors) < 10 {
							stats[id].Errors = append(stats[id].Errors, errMsg)
						}
						t.Logf("âŒ Worker-%d å†™å…¥å¤±è´¥: %v (è€—æ—¶: %s)", id, err, writeDuration)
					} else {
						stats[id].SuccessWrites++
						if writeDuration > 2*time.Second {
							t.Logf("âš ï¸  Worker-%d å†™å…¥è¾ƒæ…¢: %s", id, writeDuration)
						}
					}
				}
			}
		}(workerID)
	}

	// ç­‰å¾…æ‰€æœ‰ worker å®Œæˆ
	for i := 0; i < numWorkers; i++ {
		workerID := <-doneChan
		t.Logf("âœ“ Worker-%d å·²å®Œæˆ", workerID)
	}

	t.Log("\nâ³ ç”Ÿäº§è€…å·²å…¨éƒ¨å®Œæˆï¼Œç­‰å¾…æ¶ˆè´¹è€…æ¶ˆè´¹å‰©ä½™æ•°æ®...")

	// ç»™æ¶ˆè´¹è€…ä¸€äº›æ—¶é—´æ¶ˆè´¹å‰©ä½™æ•°æ®
	remainingTimeout := time.After(30 * time.Second)
	checkTicker := time.NewTicker(2 * time.Second)
	defer checkTicker.Stop()

consumeRemaining:
	for {
		select {
		case <-remainingTimeout:
			t.Log("âš ï¸  ç­‰å¾…è¶…æ—¶ï¼ˆ30ç§’ï¼‰ï¼Œåœæ­¢æ¶ˆè´¹è€…")
			break consumeRemaining
		case <-checkTicker.C:
			queueLen, _ := queue.Len()
			if queueLen == 0 {
				t.Log("âœ“ é˜Ÿåˆ—å·²æ¸…ç©º")
				break consumeRemaining
			}
			currentConsumerCount := atomic.LoadInt64(&consumerCount)
			t.Logf("  å‰©ä½™é˜Ÿåˆ—é•¿åº¦: %d, å·²æ¶ˆè´¹: %d", queueLen, currentConsumerCount)
		}
	}

	// åœæ­¢æ‰€æœ‰æ¶ˆè´¹è€…
	close(consumerStopChan)
	for i := 0; i < numConsumers; i++ {
		<-consumerDoneChan
	}
	t.Logf("âœ“ æ‰€æœ‰ %d ä¸ªæ¶ˆè´¹è€…å·²åœæ­¢", numConsumers)

	close(stopChan)
	time.Sleep(100 * time.Millisecond) // ç­‰å¾…ç»Ÿè®¡åç¨‹é€€å‡º

	// æœ€ç»ˆç»Ÿè®¡
	totalElapsed := time.Since(startTime)
	t.Logf("\n%s", "======================================================")
	t.Logf("ğŸ“Š æœ€ç»ˆæµ‹è¯•æŠ¥å‘Š")
	t.Logf("%s", "======================================================")

	var totalWrites, totalRecords, successWrites, failedWrites int64
	var totalDuration, maxDuration time.Duration
	minDuration := time.Hour
	var allErrors []string

	for i := 0; i < numWorkers; i++ {
		totalWrites += stats[i].TotalWrites
		totalRecords += stats[i].TotalRecords
		successWrites += stats[i].SuccessWrites
		failedWrites += stats[i].FailedWrites
		totalDuration += stats[i].TotalDuration
		if stats[i].MaxDuration > maxDuration {
			maxDuration = stats[i].MaxDuration
		}
		if stats[i].MinDuration < minDuration && stats[i].MinDuration > 0 {
			minDuration = stats[i].MinDuration
		}
		allErrors = append(allErrors, stats[i].Errors...)
	}

	finalQueueLen, _ := queue.Len()
	finalConsumerCount := atomic.LoadInt64(&consumerCount)
	finalConsumerErrors := atomic.LoadInt64(&consumerErrors)

	t.Logf("\nâ±ï¸  æ—¶é—´ç»Ÿè®¡:")
	t.Logf("  - å®é™…è¿è¡Œæ—¶é•¿: %.2f åˆ†é’Ÿ", totalElapsed.Minutes())
	t.Logf("  - æ€»å†™å…¥è€—æ—¶: %.2f ç§’", totalDuration.Seconds())
	if totalWrites > 0 {
		t.Logf("  - å¹³å‡å•æ¬¡å†™å…¥: %s", totalDuration/time.Duration(totalWrites))
	}
	t.Logf("  - æœ€å¿«/æœ€æ…¢å†™å…¥: %s / %s", minDuration, maxDuration)

	t.Logf("\nğŸ“Š ç”Ÿäº§è€…ç»Ÿè®¡:")
	t.Logf("  - æ€»å†™å…¥æ¬¡æ•°: %d", totalWrites)
	t.Logf("  - æ€»è®°å½•æ•°: %d", totalRecords)
	if totalWrites > 0 {
		t.Logf("  - æˆåŠŸæ¬¡æ•°: %d (%.2f%%)", successWrites, float64(successWrites)*100/float64(totalWrites))
		t.Logf("  - å¤±è´¥æ¬¡æ•°: %d (%.2f%%)", failedWrites, float64(failedWrites)*100/float64(totalWrites))
	}

	t.Logf("\nğŸ½ï¸  æ¶ˆè´¹è€…ç»Ÿè®¡:")
	t.Logf("  - æ€»æ¶ˆè´¹æ•°é‡: %d", finalConsumerCount)
	t.Logf("  - æ¶ˆè´¹é”™è¯¯: %d æ¬¡", finalConsumerErrors)
	if totalRecords > 0 {
		t.Logf("  - æ¶ˆè´¹å®Œæˆç‡: %.2f%%", float64(finalConsumerCount)*100/float64(totalRecords))
	}
	t.Logf("  - å¹³å‡æ¶ˆè´¹é€Ÿåº¦: %.0f æ¡/ç§’", float64(finalConsumerCount)/totalElapsed.Seconds())

	t.Logf("\nâš¡ æ€§èƒ½æŒ‡æ ‡:")
	avgProduceThroughput := float64(totalRecords) / totalElapsed.Seconds()
	avgConsumeThroughput := float64(finalConsumerCount) / totalElapsed.Seconds()
	peakThroughput := float64(numWorkers*batchSize) / writeInterval.Seconds()
	t.Logf("  - ç”Ÿäº§ååé‡: %.0f æ¡/ç§’", avgProduceThroughput)
	t.Logf("  - æ¶ˆè´¹ååé‡: %.0f æ¡/ç§’", avgConsumeThroughput)
	t.Logf("  - å³°å€¼ååé‡: %.0f æ¡/ç§’ (ç†è®º)", peakThroughput)
	t.Logf("  - ç”Ÿäº§/ç†è®ºæ¯”: %.2f%%", avgProduceThroughput/peakThroughput*100)
	if avgProduceThroughput > 0 {
		t.Logf("  - æ¶ˆè´¹/ç”Ÿäº§æ¯”: %.2f%% (>100%%è¯´æ˜æ¶ˆè´¹å¿«äºç”Ÿäº§)", avgConsumeThroughput/avgProduceThroughput*100)
	}

	t.Logf("\nğŸ“¦ é˜Ÿåˆ—çŠ¶æ€:")
	t.Logf("  - æœ€ç»ˆé˜Ÿåˆ—é•¿åº¦: %d", finalQueueLen)
	t.Logf("  - ç”Ÿäº§æ€»é‡: %d", totalRecords)
	t.Logf("  - æ¶ˆè´¹æ€»é‡: %d", finalConsumerCount)
	t.Logf("  - å‰©ä½™æœªæ¶ˆè´¹: %d", totalRecords-finalConsumerCount)
	if totalRecords > 0 {
		t.Logf("  - å‰©ä½™æ¯”ä¾‹: %.2f%%", float64(finalQueueLen)*100/float64(totalRecords))
	}

	if len(allErrors) > 0 {
		t.Logf("\nâŒ é”™è¯¯æ±‡æ€» (å‰10æ¡):")
		for i, errMsg := range allErrors {
			if i >= 10 {
				t.Logf("  ... è¿˜æœ‰ %d æ¡é”™è¯¯æœªæ˜¾ç¤º", len(allErrors)-10)
				break
			}
			t.Logf("  %d. %s", i+1, errMsg)
		}
	}

	t.Logf("\n%s", "======================================================")

	// æ€§èƒ½è¯„ä¼°
	t.Logf("\nğŸ¯ æ€§èƒ½è¯„ä¼°:")

	// ç”Ÿäº§è€…è¯„ä¼°
	if failedWrites == 0 {
		t.Log("  âœ… ç”Ÿäº§è€…: æ‰€æœ‰å†™å…¥å‡æˆåŠŸ")
	} else {
		failRate := float64(failedWrites) * 100 / float64(totalWrites)
		if failRate > 5 {
			t.Errorf("  âŒ ç”Ÿäº§è€…å¤±è´¥ç‡è¿‡é«˜: %.2f%%", failRate)
		} else {
			t.Logf("  âš ï¸  ç”Ÿäº§è€…æœ‰å°‘é‡å¤±è´¥: %.2f%%", failRate)
		}
	}

	// æ¶ˆè´¹è€…è¯„ä¼°
	if totalRecords > 0 {
		consumeRate := float64(finalConsumerCount) * 100 / float64(totalRecords)
		if consumeRate >= 99 {
			t.Log("  âœ… æ¶ˆè´¹è€…: æ¶ˆè´¹å®Œæˆç‡ä¼˜ç§€ (â‰¥99%)")
		} else if consumeRate >= 95 {
			t.Log("  âœ… æ¶ˆè´¹è€…: æ¶ˆè´¹å®Œæˆç‡è‰¯å¥½ (â‰¥95%)")
		} else if consumeRate >= 90 {
			t.Logf("  âš ï¸  æ¶ˆè´¹è€…: æ¶ˆè´¹å®Œæˆç‡ä¸€èˆ¬ (%.2f%%, â‰¥90%%)", consumeRate)
		} else {
			t.Logf("  âŒ æ¶ˆè´¹è€…: æ¶ˆè´¹å®Œæˆç‡è¾ƒä½ (%.2f%%, <90%%)", consumeRate)
		}
	}

	// æ•´ä½“è¯„ä¼°
	if finalQueueLen == 0 && failedWrites == 0 {
		t.Log("  ğŸ‰ æ•´ä½“è¯„ä¼°: å®Œç¾ï¼é˜Ÿåˆ—å·²æ¸…ç©ºï¼Œæ— å¤±è´¥å†™å…¥")
	} else if finalQueueLen < int64(batchSize) && failedWrites == 0 {
		t.Log("  âœ… æ•´ä½“è¯„ä¼°: ä¼˜ç§€ï¼å‰©ä½™æ•°æ®å°‘ï¼Œæ— å¤±è´¥å†™å…¥")
	} else {
		t.Log("  âš ï¸  æ•´ä½“è¯„ä¼°: å¯æ¥å—ï¼Œä½†ä»æœ‰ä¼˜åŒ–ç©ºé—´")
	}
}

// TestConcurrentWrite_BatchConsume æ‰¹é‡æ¶ˆè´¹æµ‹è¯•
func TestConcurrentWrite_BatchConsume(t *testing.T) {
	single, err := redistools.InitSingle("r-bp1dqgkbwcsqyto3lcpd.redis.rds.aliyuncs.com:6379", "r-bp1dqgkbwcsqyto3lc", "4553283@wch", 0)
	if err != nil {
		t.Error(err)
		return
	}

	const (
		numWorkers       = 10
		numConsumers     = 5 // æ‰¹é‡æ¶ˆè´¹å¯ä»¥ç”¨æ›´å°‘çš„æ¶ˆè´¹è€…
		batchSize        = 1000
		consumeBatchSize = 100 // æ¯æ¬¡æ‰¹é‡æ¶ˆè´¹100æ¡
		writeInterval    = 5 * time.Second
		testDuration     = 2 * time.Minute // 2åˆ†é’Ÿæµ‹è¯•
	)

	t.Logf("=== æ‰¹é‡æ¶ˆè´¹å‹åŠ›æµ‹è¯•é…ç½® ===")
	t.Logf("  ç”Ÿäº§è€…æ•°: %d, æ¶ˆè´¹è€…æ•°: %d", numWorkers, numConsumers)
	t.Logf("  ç”Ÿäº§æ‰¹æ¬¡: %d æ¡, æ¶ˆè´¹æ‰¹æ¬¡: %d æ¡", batchSize, consumeBatchSize)
	t.Logf("  æµ‹è¯•æ—¶é•¿: %s", testDuration)
	t.Logf("")

	queue := NewRedisQueue[dv]("batch_consume_test", single, 0, 30*time.Second)

	// æ¸…ç©ºæ—§æ•°æ®
	t.Log("æ¸…ç©ºæ—§æ•°æ®...")
	for {
		_, err := queue.Dequeue()
		if err != nil {
			break
		}
	}

	var producedCount, consumedCount int64
	startTime := time.Now()
	stopChan := make(chan struct{})
	consumerStopChan := make(chan struct{})
	consumerDoneChan := make(chan bool, numConsumers)
	producerDoneChan := make(chan bool, numWorkers)

	// å¯åŠ¨æ‰¹é‡æ¶ˆè´¹è€…
	t.Logf("ğŸ”„ å¯åŠ¨ %d ä¸ªæ‰¹é‡æ¶ˆè´¹è€…...", numConsumers)
	for consumerID := 0; consumerID < numConsumers; consumerID++ {
		go func(id int) {
			defer func() {
				consumerDoneChan <- true
			}()

			for {
				select {
				case <-consumerStopChan:
					return
				default:
					// æ‰¹é‡æ¶ˆè´¹
					items, err := queue.DequeueBatch(consumeBatchSize)
					if err != nil || len(items) == 0 {
						time.Sleep(50 * time.Millisecond) // é˜Ÿåˆ—ä¸ºç©ºï¼Œç¨ç­‰
						continue
					}

					count := atomic.AddInt64(&consumedCount, int64(len(items)))
					if count%10000 == 0 {
						t.Logf("ğŸ½ï¸  [æ¶ˆè´¹è€…-%d] æ‰¹é‡æ¶ˆè´¹: æœ¬æ¬¡ %d æ¡, ç´¯è®¡ %d æ¡", id, len(items), count)
					}
				}
			}
		}(consumerID)
	}

	// å¯åŠ¨ç”Ÿäº§è€…
	t.Logf("ğŸš€ å¯åŠ¨ %d ä¸ªç”Ÿäº§è€…...", numWorkers)
	for workerID := 0; workerID < numWorkers; workerID++ {
		go func(id int) {
			ticker := time.NewTicker(writeInterval)
			defer ticker.Stop()
			timeout := time.After(testDuration)

			for {
				select {
				case <-timeout:
					producerDoneChan <- true
					return
				case <-ticker.C:
					batch := make([]dv, batchSize)
					for i := 0; i < batchSize; i++ {
						batch[i] = dv{
							Abcdefgh: "2ba2d4bd-af24-48ae-9e66-22d1c30c9f01",
							Abcdef:   true,
						}
					}

					if err := queue.Enqueue(batch); err == nil {
						atomic.AddInt64(&producedCount, int64(batchSize))
					}
				}
			}
		}(workerID)
	}

	// å®šæœŸè¾“å‡ºç»Ÿè®¡
	go func() {
		ticker := time.NewTicker(15 * time.Second)
		defer ticker.Stop()

		for {
			select {
			case <-stopChan:
				return
			case <-ticker.C:
				elapsed := time.Since(startTime)
				produced := atomic.LoadInt64(&producedCount)
				consumed := atomic.LoadInt64(&consumedCount)
				queueLen, _ := queue.Len()

				produceSpeed := float64(produced) / elapsed.Seconds()
				consumeSpeed := float64(consumed) / elapsed.Seconds()

				t.Logf("\nâ±ï¸  [æ‰¹é‡æ¶ˆè´¹è¿›åº¦] è¿è¡Œ: %.1f ç§’", elapsed.Seconds())
				t.Logf("  ç”Ÿäº§: %d æ¡ (%.0f æ¡/ç§’)", produced, produceSpeed)
				t.Logf("  æ¶ˆè´¹: %d æ¡ (%.0f æ¡/ç§’)", consumed, consumeSpeed)
				t.Logf("  é˜Ÿåˆ—: %d æ¡, æ¶ˆè´¹ç‡: %.2f%%", queueLen, consumeSpeed/produceSpeed*100)
				t.Logf("")
			}
		}
	}()

	// ç­‰å¾…ç”Ÿäº§è€…å®Œæˆ
	for i := 0; i < numWorkers; i++ {
		<-producerDoneChan
	}
	t.Log("âœ“ æ‰€æœ‰ç”Ÿäº§è€…å·²å®Œæˆ")

	// ç­‰å¾…æ¶ˆè´¹å‰©ä½™æ•°æ®
	time.Sleep(10 * time.Second)
	close(consumerStopChan)
	for i := 0; i < numConsumers; i++ {
		<-consumerDoneChan
	}

	close(stopChan)
	time.Sleep(100 * time.Millisecond)

	// æœ€ç»ˆç»Ÿè®¡
	totalElapsed := time.Since(startTime)
	finalProduced := atomic.LoadInt64(&producedCount)
	finalConsumed := atomic.LoadInt64(&consumedCount)
	finalQueueLen, _ := queue.Len()

	t.Logf("\n%s", "======================================================")
	t.Logf("ğŸ“Š æ‰¹é‡æ¶ˆè´¹æµ‹è¯•æŠ¥å‘Š")
	t.Logf("%s", "======================================================")
	t.Logf("\nè€—æ—¶: %.2f ç§’", totalElapsed.Seconds())
	t.Logf("ç”Ÿäº§: %d æ¡ (%.0f æ¡/ç§’)", finalProduced, float64(finalProduced)/totalElapsed.Seconds())
	t.Logf("æ¶ˆè´¹: %d æ¡ (%.0f æ¡/ç§’)", finalConsumed, float64(finalConsumed)/totalElapsed.Seconds())
	t.Logf("å‰©ä½™: %d æ¡", finalQueueLen)
	t.Logf("æ¶ˆè´¹å®Œæˆç‡: %.2f%%", float64(finalConsumed)*100/float64(finalProduced))

	if float64(finalConsumed)/float64(finalProduced) >= 0.95 {
		t.Log("âœ… æ‰¹é‡æ¶ˆè´¹æ€§èƒ½ä¼˜ç§€ï¼")
	}
}

// TestConcurrentWrite_ShortTest çŸ­æ—¶å¹¶å‘æµ‹è¯•ï¼ˆ1åˆ†é’Ÿï¼Œç”¨äºå¿«é€ŸéªŒè¯ï¼‰
func TestConcurrentWrite_ShortTest(t *testing.T) {
	single, err := redistools.InitSingle("127.0.0.1:6379", "", "", 0)
	if err != nil {
		t.Error(err)
		return
	}

	const (
		numWorkers    = 5
		batchSize     = 500
		writeInterval = 5 * time.Second
		testDuration  = 1 * time.Minute
	)

	t.Logf("ğŸš€ å¿«é€Ÿå¹¶å‘æµ‹è¯• (1åˆ†é’Ÿ)")
	t.Logf("  Workers: %d, æ¯æ‰¹: %d æ¡, é—´éš”: %s", numWorkers, batchSize, writeInterval)

	queue := NewRedisQueue[dv]("short_test", single, 0, 10*time.Second)

	// æ¸…ç©ºæ—§æ•°æ®
	for {
		_, err := queue.Dequeue()
		if err != nil {
			break
		}
	}

	startTime := time.Now()
	var successCount, failCount int64
	doneChan := make(chan bool, numWorkers)

	for workerID := 0; workerID < numWorkers; workerID++ {
		go func(id int) {
			ticker := time.NewTicker(writeInterval)
			defer ticker.Stop()
			timeout := time.After(testDuration)

			for {
				select {
				case <-timeout:
					doneChan <- true
					return
				case <-ticker.C:
					batch := make([]dv, batchSize)
					for i := 0; i < batchSize; i++ {
						batch[i] = dv{Abcdefgh: "test", Abcdef: true}
					}

					if err := queue.Enqueue(batch); err != nil {
						atomic.AddInt64(&failCount, 1)
						t.Logf("âŒ Worker-%d å¤±è´¥: %v", id, err)
					} else {
						atomic.AddInt64(&successCount, 1)
					}
				}
			}
		}(workerID)
	}

	for i := 0; i < numWorkers; i++ {
		<-doneChan
	}

	elapsed := time.Since(startTime)
	finalSuccessCount := atomic.LoadInt64(&successCount)
	finalFailCount := atomic.LoadInt64(&failCount)
	totalWrites := finalSuccessCount + finalFailCount
	totalRecords := finalSuccessCount * int64(batchSize)
	queueLen, _ := queue.Len()

	t.Logf("\nâœ“ æµ‹è¯•å®Œæˆ (%.1f ç§’)", elapsed.Seconds())
	t.Logf("  æˆåŠŸ: %d, å¤±è´¥: %d (æ€»è®¡: %d æ¬¡)", finalSuccessCount, finalFailCount, totalWrites)
	t.Logf("  æ€»è®°å½•: %d, é€Ÿåº¦: %.0f æ¡/ç§’", totalRecords, float64(totalRecords)/elapsed.Seconds())
	t.Logf("  é˜Ÿåˆ—é•¿åº¦: %d", queueLen)

	if finalFailCount > 0 {
		t.Errorf("å­˜åœ¨å¤±è´¥çš„å†™å…¥: %d æ¬¡", finalFailCount)
	}
}
