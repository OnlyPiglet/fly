package main

import (
	"encoding/json"
	"fmt"
	"time"

	"github.com/OnlyPiglet/fly/kafkatools"
)

// Event æµ‹è¯•äº‹ä»¶ç»“æ„ä½“
type Event struct {
	ID        int64     `json:"id"`
	Name      string    `json:"name"`
	Timestamp time.Time `json:"timestamp"`
	UserID    int64     `json:"user_id"`
}

func main() {
	fmt.Println("=== Kafka Single Broker Test ===")

	// å°è¯•ä½¿ç”¨å†…éƒ¨ Docker åœ°å€ï¼ˆä»é”™è¯¯ä¿¡æ¯ä¸­è·å¾—ï¼‰
	config := &kafkatools.KafkaConfig{
		Brokers: []string{
			"172.21.52.178:19091",
			"172.21.52.178:19092", 
			"172.21.52.178:19093",
		},
		ClientID:     "docker-internal-test-client",
		KafkaVersion: "3.7.1", // æ ¹æ®ä½ çš„ APP_VERSION
	}

	fmt.Printf("Connecting to Kafka broker: %v\n", config.Brokers)

	client, err := kafkatools.NewKafkaClient(config)
	if err != nil {
		fmt.Printf("âŒ Failed to create kafka client: %v\n", err)
		return
	}
	defer client.Close()

	fmt.Println("âœ… Kafka client created successfully")

	// 1. æµ‹è¯•å‘é€å•æ¡æ¶ˆæ¯ï¼ˆè‡ªåŠ¨åˆ›å»ºtopicï¼‰
	fmt.Println("\n=== Testing ProduceMessage with auto-create ===")
	testTopic := "single-test-topic"
	message := []byte(fmt.Sprintf(`{"test": "single broker test", "timestamp": "%s"}`, time.Now().Format(time.RFC3339)))

	err = client.ProduceMessage(testTopic, message, kafkatools.ProduceOptions{
		Key: "test-key",
		Headers: map[string]string{
			"source": "single-test",
			"type":   "test-message",
		},
	})
	if err != nil {
		fmt.Printf("âŒ Failed to produce message: %v\n", err)
		return
	}
	fmt.Println("âœ… Single message sent successfully")

	// 2. éªŒè¯topicæ˜¯å¦è¢«åˆ›å»º
	fmt.Println("\n=== Verifying topic creation ===")
	exists, err := client.TopicExists(testTopic)
	if err != nil {
		fmt.Printf("âŒ Failed to check topic existence: %v\n", err)
		return
	}
	
	if exists {
		fmt.Printf("âœ… Topic '%s' was auto-created\n", testTopic)
		
		// è·å–topicè¯¦æƒ…
		topics, err := client.ListTopics()
		if err == nil {
			if detail, found := topics[testTopic]; found {
				fmt.Printf("  Topic details: %d partitions, replication factor %d\n", 
					detail.NumPartitions, detail.ReplicationFactor)
			}
		}
	} else {
		fmt.Printf("âŒ Topic '%s' was not created\n", testTopic)
	}

	// 3. æµ‹è¯•æ‰¹é‡å‘é€ï¼ˆè‡ªåŠ¨åˆ›å»ºtopicï¼‰
	fmt.Println("\n=== Testing ProduceBatch with auto-create ===")
	batchTopic := "batch-test-topic"
	
	events := []Event{
		{ID: 1, Name: "user_login", Timestamp: time.Now(), UserID: 100},
		{ID: 2, Name: "page_view", Timestamp: time.Now(), UserID: 101},
		{ID: 3, Name: "purchase", Timestamp: time.Now(), UserID: 102},
	}

	serializer := func(event Event) ([]byte, error) {
		return json.Marshal(event)
	}

	err = kafkatools.ProduceBatch(client, batchTopic, events, serializer, kafkatools.ProduceOptions{
		Headers: map[string]string{
			"source": "batch-test",
			"count":  fmt.Sprintf("%d", len(events)),
		},
	})
	if err != nil {
		fmt.Printf("âŒ Failed to produce batch: %v\n", err)
		return
	}
	fmt.Printf("âœ… Batch of %d events sent successfully\n", len(events))

	// 4. åˆ—å‡ºæ‰€æœ‰topics
	fmt.Println("\n=== Listing all topics ===")
	topics, err := client.ListTopics()
	if err != nil {
		fmt.Printf("âŒ Failed to list topics: %v\n", err)
		return
	}

	fmt.Printf("âœ… Found %d topics:\n", len(topics))
	for name, detail := range topics {
		fmt.Printf("  - %s: %d partitions, replication factor %d\n", 
			name, detail.NumPartitions, detail.ReplicationFactor)
	}

	// 5. æ¸…ç†æµ‹è¯•topics
	fmt.Println("\n=== Cleaning up test topics ===")
	err = client.DeleteTopics([]string{testTopic, batchTopic})
	if err != nil {
		fmt.Printf("âš ï¸  Failed to cleanup topics: %v\n", err)
	} else {
		fmt.Println("âœ… Test topics cleaned up successfully")
	}

	fmt.Println("\nğŸ‰ Single broker test completed successfully!")
}
